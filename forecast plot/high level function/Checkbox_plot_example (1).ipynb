{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OA29p8MNuvHx",
    "outputId": "4027c57b-1b87-4186-ea97-a524c99ccc32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dash in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: flask-compress in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from dash) (1.4.0)\n",
      "Requirement already satisfied: dash-table==5.0.0 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from dash) (5.0.0)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from dash) (2.0.0)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from dash) (2.0.0)\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from dash) (5.1.0)\n",
      "Requirement already satisfied: Flask>=1.0.4 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from dash) (1.1.2)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from Flask>=1.0.4->dash) (1.0.1)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from Flask>=1.0.4->dash) (2.11.2)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from Flask>=1.0.4->dash) (7.1.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from Flask>=1.0.4->dash) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from Jinja2>=2.10.1->Flask>=1.0.4->dash) (1.1.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from plotly>=5.0.0->dash) (8.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from plotly>=5.0.0->dash) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E2-jUhe2upS3",
    "outputId": "132224e1-44a7-4b24-d72a-381e280c4bb4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter_dash in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: ansi2html in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from jupyter_dash) (0.0.0)\n",
      "Requirement already satisfied: retrying in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from jupyter_dash) (1.3.3)\n",
      "Requirement already satisfied: flask in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from jupyter_dash) (1.1.2)\n",
      "Requirement already satisfied: ipykernel in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from jupyter_dash) (5.4.2)\n",
      "Requirement already satisfied: requests in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from jupyter_dash) (2.25.1)\n",
      "Requirement already satisfied: ipython in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from jupyter_dash) (7.19.0)\n",
      "Requirement already satisfied: dash in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from jupyter_dash) (2.0.0)\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from dash->jupyter_dash) (5.1.0)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from dash->jupyter_dash) (2.0.0)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from dash->jupyter_dash) (2.0.0)\n",
      "Requirement already satisfied: flask-compress in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from dash->jupyter_dash) (1.4.0)\n",
      "Requirement already satisfied: dash-table==5.0.0 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from dash->jupyter_dash) (5.0.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from flask->jupyter_dash) (1.0.1)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from flask->jupyter_dash) (2.11.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from flask->jupyter_dash) (1.1.0)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from flask->jupyter_dash) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from Jinja2>=2.10.1->flask->jupyter_dash) (1.1.1)\n",
      "Requirement already satisfied: six in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from plotly>=5.0.0->dash->jupyter_dash) (1.15.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from plotly>=5.0.0->dash->jupyter_dash) (8.0.1)\n",
      "Requirement already satisfied: jupyter-client in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from ipykernel->jupyter_dash) (6.1.7)\n",
      "Requirement already satisfied: tornado>=4.2 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from ipykernel->jupyter_dash) (6.1)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from ipykernel->jupyter_dash) (5.0.5)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from ipython->jupyter_dash) (0.7.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from ipython->jupyter_dash) (0.4.4)\n",
      "Requirement already satisfied: backcall in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from ipython->jupyter_dash) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from ipython->jupyter_dash) (49.6.0.post20201009)\n",
      "Requirement already satisfied: decorator in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from ipython->jupyter_dash) (4.4.2)\n",
      "Requirement already satisfied: pygments in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from ipython->jupyter_dash) (2.7.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from ipython->jupyter_dash) (3.0.8)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from ipython->jupyter_dash) (0.14.1)\n",
      "Requirement already satisfied: parso>=0.5.0 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from jedi>=0.10->ipython->jupyter_dash) (0.5.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->jupyter_dash) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from traitlets>=4.1.0->ipykernel->jupyter_dash) (0.2.0)\n",
      "Requirement already satisfied: pyzmq>=13 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from jupyter-client->ipykernel->jupyter_dash) (20.0.0)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from jupyter-client->ipykernel->jupyter_dash) (4.7.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from jupyter-client->ipykernel->jupyter_dash) (2.8.1)\n",
      "Requirement already satisfied: pywin32>=1.0 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->jupyter_dash) (228)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from requests->jupyter_dash) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from requests->jupyter_dash) (2021.10.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from requests->jupyter_dash) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from requests->jupyter_dash) (1.26.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install jupyter_dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "STZhESm5vSlQ",
    "outputId": "4e704972-a5bd-4cca-f120-a35e900fb08e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dash_bootstrap_components in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (0.8.3)\n",
      "Requirement already satisfied: dash>=1.9.0 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from dash_bootstrap_components) (2.0.0)\n",
      "Requirement already satisfied: flask-compress in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from dash>=1.9.0->dash_bootstrap_components) (1.4.0)\n",
      "Requirement already satisfied: dash-table==5.0.0 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from dash>=1.9.0->dash_bootstrap_components) (5.0.0)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from dash>=1.9.0->dash_bootstrap_components) (2.0.0)\n",
      "Requirement already satisfied: Flask>=1.0.4 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from dash>=1.9.0->dash_bootstrap_components) (1.1.2)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from dash>=1.9.0->dash_bootstrap_components) (2.0.0)\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from dash>=1.9.0->dash_bootstrap_components) (5.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from Flask>=1.0.4->dash>=1.9.0->dash_bootstrap_components) (1.0.1)\n",
      "Requirement already satisfied: click>=5.1 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from Flask>=1.0.4->dash>=1.9.0->dash_bootstrap_components) (7.1.2)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from Flask>=1.0.4->dash>=1.9.0->dash_bootstrap_components) (2.11.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from Flask>=1.0.4->dash>=1.9.0->dash_bootstrap_components) (1.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from Jinja2>=2.10.1->Flask>=1.0.4->dash>=1.9.0->dash_bootstrap_components) (1.1.1)\n",
      "Requirement already satisfied: six in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from plotly>=5.0.0->dash>=1.9.0->dash_bootstrap_components) (1.15.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\mehakdeep kaur\\anaconda\\anaconda_3\\lib\\site-packages (from plotly>=5.0.0->dash>=1.9.0->dash_bootstrap_components) (8.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install dash_bootstrap_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "KfqMiw6pvJL2"
   },
   "outputs": [],
   "source": [
    "from jupyter_dash import JupyterDash\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State, ClientsideFunction\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_core_components as dcc\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.express as px\n",
    "# pd.options.plotting.backend = \"plotly\"\n",
    "import plotly.offline as py\n",
    "from plotly import subplots\n",
    "\n",
    "from datetime import datetime\n",
    "from math import sqrt\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import tensorflow.keras\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "tT6TtWoV-3s6"
   },
   "outputs": [],
   "source": [
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "tNco978w-51X"
   },
   "outputs": [],
   "source": [
    "def pred_lstm_uni(data_source = 'wri', reservoir_name = 'KRS', noofdays = 30):\n",
    "  data_source = data_source.lower()\n",
    "  if data_source == 'wri':\n",
    "    df = pd.read_csv('/Wave2Web2021/data/processed/WRI/all_wri_jan2011_dec2020.csv', index_col=0)\n",
    "    df = df[df['RESERVOIR']==reservoir_name]\n",
    "    df = df.drop([\"RESERVOIR\"], axis = 1)\n",
    "    df[\"PRESENT_STORAGE_TMC\"] = pd.to_numeric(df[\"PRESENT_STORAGE_TMC\"], errors='coerce')\n",
    "    df = df.sort_values(by=\"DATE\")\n",
    "    df['DATE']=pd.to_datetime(df['DATE'])\n",
    "    df.set_index('DATE', inplace=True)\n",
    "    df.drop(df.columns[[0,2,3,4,5]], axis=1, inplace=True)\n",
    "    \n",
    "  else:\n",
    "    if data_source == 'indiawris':\n",
    "      df = pd.read_csv('/Wave2Web2021/data/processed/IndiaWRIS/all_indiawris_jan2001_may2021.csv', index_col=0)\n",
    "      df = df[df['RESERVOIR']==reservoir_name]\n",
    "      df = df.drop([\"RESERVOIR\"], axis = 1)\n",
    "      df[\"PRESENT_STORAGE_TMC\"] = pd.to_numeric(df[\"PRESENT_STORAGE_TMC\"], errors='coerce')\n",
    "      df = df.sort_values(by=\"DATE\")\n",
    "      df['DATE']=pd.to_datetime(df['DATE'])\n",
    "      df.set_index('DATE', inplace=True)\n",
    "      df.drop(df.columns[[0,1,3]], axis=1, inplace=True)\n",
    "    else:\n",
    "      print(\"Data Source not found.\")\n",
    "      return \n",
    "\n",
    "  values = df.values\n",
    "  # ensure all data is float\n",
    "  values = values.astype('float32')\n",
    "  # normalize features\n",
    "  scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "  scaled = scaler.fit_transform(values)\n",
    "  # frame as supervised learning\n",
    "  reframed = series_to_supervised(scaled, 1, 1) \n",
    "  # split into train and test sets\n",
    "  values = reframed.values\n",
    "  n_train_years = values.shape[0] - 366\n",
    "  train = values[:n_train_years, :]\n",
    "  test = values[n_train_years:, :]\n",
    "  # split into input and outputs\n",
    "  train_X, train_y = train[:, :-1], train[:, -1]\n",
    "  test_X, test_y = test[:, :-1], test[:, -1]\n",
    "  # reshape input to be 3D [samples, timesteps, features]\n",
    "  train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "  test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "  # design network\n",
    "  new_uni_model = Sequential()\n",
    "  new_uni_model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "  new_uni_model.add(Dense(1))\n",
    "  new_uni_model.compile(loss='mae', optimizer='adam')\n",
    "  \n",
    "  new_uni_model.load_weights('/Wave2Web2021/fitted_models/lstm_uni_weights.h5')\n",
    "  # make a prediction\n",
    "  new_yhat = new_uni_model.predict(test_X)\n",
    "  test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "  # invert scaling for forecast\n",
    "  new_inv_yhat = np.concatenate((new_yhat, test_X[:, 1:]), axis=1)\n",
    "  new_inv_yhat = scaler.inverse_transform(new_inv_yhat)\n",
    "  new_inv_yhat = new_inv_yhat[:,0]\n",
    "  # invert scaling for actual\n",
    "  test_y = test_y.reshape((len(test_y), 1))\n",
    "  new_inv_y = np.concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "  new_inv_y = scaler.inverse_transform(new_inv_y)\n",
    "  new_inv_y = new_inv_y[:,0]\n",
    "  # calculate RMSE\n",
    "  rmse = sqrt(mean_squared_error(new_inv_y[:90], new_inv_yhat[:90]))\n",
    "  print('LSTM 90 days RMSE: %.3f' % rmse)\n",
    "  rmse = sqrt(mean_squared_error(new_inv_y, new_inv_yhat))\n",
    "  print('LSTM 1 year RMSE: %.3f' % rmse)\n",
    "\n",
    "  pred_list = []\n",
    "  n_input = 1\n",
    "  n_features = 1\n",
    "  batch_X = test_X[-n_input:].reshape((n_input, 1, n_features))\n",
    "  n_pred = noofdays\n",
    "\n",
    "  for i in range(n_pred):\n",
    "    yhat = new_uni_model.predict(batch_X)\n",
    "    batch = batch_X\n",
    "    batch = batch.reshape(batch.shape[0], batch.shape[2])\n",
    "    inv_yhat = np.concatenate((yhat, batch[:, 1:]), axis=1)\n",
    "    inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "    inv_yhat = inv_yhat[:,0]\n",
    "    pred_list.append(inv_yhat[-1])\n",
    "    batch_X = np.append(batch_X, batch_X[0,0,0])\n",
    "    batch_X = np.delete(batch_X,[0,0,0])\n",
    "    batch_X[n_input-1] = yhat[-1]\n",
    "    batch_X = batch_X.reshape((n_input, 1, n_features))\n",
    "    \n",
    "  add_dates = [df.index[-1] + pd.DateOffset(days=x) for x in range(0,n_pred+1) ]\n",
    "  future_dates = pd.DataFrame(index=add_dates[1:],columns=df.columns)\n",
    "\n",
    "  df_predict = pd.DataFrame(pred_list, index=future_dates[-n_pred:].index, columns=['FORECAST'])\n",
    "\n",
    "  df_predict.index = pd.to_datetime(df_predict.index)\n",
    "  df.index = pd.to_datetime(df.index)\n",
    "  dfans = pd.concat([df, df_predict], axis=1, join=\"outer\")\n",
    "  return rmse, dfans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "ZKJ2iF9s-8E0"
   },
   "outputs": [],
   "source": [
    "def pred_svr_uni(data_source = 'wri', reservoir_name = 'KRS', noofdays = 30):\n",
    "  data_source = data_source.lower()\n",
    "  if data_source == 'wri':\n",
    "    df = pd.read_csv('/Wave2Web2021/data/processed/WRI/all_wri_jan2011_dec2020.csv', index_col=0)\n",
    "    df = df[df['RESERVOIR']==reservoir_name]\n",
    "    df = df.drop([\"RESERVOIR\"], axis = 1)\n",
    "    df[\"PRESENT_STORAGE_TMC\"] = pd.to_numeric(df[\"PRESENT_STORAGE_TMC\"], errors='coerce')\n",
    "    df = df.sort_values(by=\"DATE\")\n",
    "    df['DATE']=pd.to_datetime(df['DATE'])\n",
    "    df.set_index('DATE', inplace=True)\n",
    "    df.drop(df.columns[[0,2,3,4,5]], axis=1, inplace=True)\n",
    "    \n",
    "  else:\n",
    "    if data_source == 'indiawris':\n",
    "      df = pd.read_csv('/Wave2Web2021/data/processed/IndiaWRIS/all_indiawris_jan2001_may2021.csv', index_col=0)\n",
    "      df = df[df['RESERVOIR']==reservoir_name]\n",
    "      df = df.drop([\"RESERVOIR\"], axis = 1)\n",
    "      df[\"PRESENT_STORAGE_TMC\"] = pd.to_numeric(df[\"PRESENT_STORAGE_TMC\"], errors='coerce')\n",
    "      df = df.sort_values(by=\"DATE\")\n",
    "      df['DATE']=pd.to_datetime(df['DATE'])\n",
    "      df.set_index('DATE', inplace=True)\n",
    "      df.drop(df.columns[[0,1,3]], axis=1, inplace=True)\n",
    "    else:\n",
    "      print(\"Data Source not found.\")\n",
    "      return \n",
    "\n",
    "  values = df.values\n",
    "  # ensure all data is float\n",
    "  values = values.astype('float32')\n",
    "  # normalize features\n",
    "  scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "  scaled = scaler.fit_transform(values)\n",
    "  # frame as supervised learning\n",
    "  reframed = series_to_supervised(scaled, 1, 1) \n",
    "  # split into train and test sets\n",
    "  values = reframed.values\n",
    "  n_test= 366\n",
    "  X = reframed[['var1(t-1)']]\n",
    "  y = reframed[['var1(t)']]\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = n_test, random_state=42, shuffle = False)\n",
    "  filename = '\\Wave2Web2021\\fitted_models\\SVR_UNI.sav'\n",
    "  lm = pickle.load(open(filename, 'rb'))\n",
    "  # make a prediction\n",
    "  y_pred = lm.predict(X_test)\n",
    "  y_pred = y_pred.reshape(-1,1)\n",
    "  # invert scaling for forecast\n",
    "  y_pred= scaler.inverse_transform(y_pred)\n",
    "  # invert scaling for actual\n",
    "  y_test=scaler.inverse_transform(y_test)\n",
    "  # calculate RMSE\n",
    "  rmse = sqrt(mean_squared_error(y_test[:90], y_pred[:90]))\n",
    "  print('SVR 90 days RMSE: %.3f' % rmse)\n",
    "  rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "  print('SVR 1 year RMSE: %.3f' % rmse)\n",
    "  \n",
    "  pred_list = []\n",
    "  n_input = 1\n",
    "  n_features = 1\n",
    "  batch_X = X_test[-n_input:]\n",
    "  n_pred = noofdays\n",
    "\n",
    "  for i in range(n_pred):\n",
    "    yhat = lm.predict(batch_X)\n",
    "    batch_X = np.append(batch_X, yhat)\n",
    "    batch_X = np.delete(batch_X,[0,0])\n",
    "    batch_X = batch_X.reshape(-1,1)\n",
    "    inv_yhat = scaler.inverse_transform(yhat.reshape(-1,1))\n",
    "    pred_list.append(inv_yhat[-1])\n",
    "    \n",
    "  add_dates = [df.index[-1] + pd.DateOffset(days=x) for x in range(0,n_pred+1) ]\n",
    "  future_dates = pd.DataFrame(index=add_dates[1:],columns=df.columns)\n",
    "\n",
    "  df_predict = pd.DataFrame(pred_list, index=future_dates[-n_pred:].index, columns=['FORECAST'])\n",
    "  \n",
    "  df_predict.index = pd.to_datetime(df_predict.index)\n",
    "  df.index = pd.to_datetime(df.index)\n",
    "  dfans = pd.concat([df, df_predict], axis=1, join=\"outer\")\n",
    "  return rmse, dfans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ITKpouj8--aH"
   },
   "outputs": [],
   "source": [
    "def pred_xgb_uni(data_source = 'wri', reservoir_name = 'KRS', noofdays = 30):\n",
    "  data_source = data_source.lower()\n",
    "  if data_source == 'wri':\n",
    "    df = pd.read_csv('/Wave2Web2021/data/processed/WRI/all_wri_jan2011_dec2020.csv', index_col=0)\n",
    "    df = df[df['RESERVOIR']==reservoir_name]\n",
    "    df = df.drop([\"RESERVOIR\"], axis = 1)\n",
    "    df[\"PRESENT_STORAGE_TMC\"] = pd.to_numeric(df[\"PRESENT_STORAGE_TMC\"], errors='coerce')\n",
    "    df = df.sort_values(by=\"DATE\")\n",
    "    df['DATE']=pd.to_datetime(df['DATE'])\n",
    "    df.set_index('DATE', inplace=True)\n",
    "    df.drop(df.columns[[0,2,3,4,5]], axis=1, inplace=True)\n",
    "    \n",
    "  else:\n",
    "    if data_source == 'indiawris':\n",
    "      df = pd.read_csv('/Wave2Web2021/data/processed/IndiaWRIS/all_indiawris_jan2001_may2021.csv', index_col=0)\n",
    "      df = df[df['RESERVOIR']==reservoir_name]\n",
    "      df = df.drop([\"RESERVOIR\"], axis = 1)\n",
    "      df[\"PRESENT_STORAGE_TMC\"] = pd.to_numeric(df[\"PRESENT_STORAGE_TMC\"], errors='coerce')\n",
    "      df = df.sort_values(by=\"DATE\")\n",
    "      df['DATE']=pd.to_datetime(df['DATE'])\n",
    "      df.set_index('DATE', inplace=True)\n",
    "      df.drop(df.columns[[0,1,3]], axis=1, inplace=True)\n",
    "    else:\n",
    "      print(\"Data Source not found.\")\n",
    "      return \n",
    "\n",
    "  values = df.values\n",
    "  # ensure all data is float\n",
    "  values = values.astype('float32')\n",
    "  # normalize features\n",
    "  scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "  scaled = scaler.fit_transform(values.reshape(-1,1))\n",
    "  # frame as supervised learning\n",
    "  reframed = series_to_supervised(scaled, 1, 1) \n",
    "  # split into train and test sets\n",
    "  values = reframed.values\n",
    "  n_test= 366\n",
    "  X = reframed[['var1(t-1)']]\n",
    "  y = reframed[['var1(t)']]\n",
    "  from sklearn.model_selection import train_test_split\n",
    "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = n_test, random_state=42, shuffle = False)\n",
    "  filename = '/Wave2Web2021/fitted_models/XGB_uni.sav'\n",
    "  lm = pickle.load(open(filename, 'rb'))\n",
    "  # make a prediction\n",
    "  y_pred = lm.predict(X_test)\n",
    "  y_pred = y_pred.reshape(-1,1)\n",
    "  # invert scaling for forecast\n",
    "  y_pred= scaler.inverse_transform(y_pred)\n",
    "  # invert scaling for actual\n",
    "  y_test=scaler.inverse_transform(y_test)\n",
    "  # calculate RMSE\n",
    "  rmse = sqrt(mean_squared_error(y_test[:90], y_pred[:90]))\n",
    "  print('XGBoost 90 days RMSE: %.3f' % rmse)\n",
    "  rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "  print('XGBoost 1 year RMSE: %.3f' % rmse)\n",
    "  \n",
    "  pred_list = []\n",
    "  n_input = 1\n",
    "  n_features = 1\n",
    "  batch_X = X_test[-n_input:]\n",
    "  n_pred = noofdays\n",
    "\n",
    "  for i in range(n_pred):\n",
    "    yhat = lm.predict(batch_X)\n",
    "    batch_X = np.append(batch_X, yhat)\n",
    "    batch_X = np.delete(batch_X,[0,0])\n",
    "    batch_X = batch_X.reshape(-1,1)\n",
    "    batch_X = pd.DataFrame(data=batch_X, columns=['var1(t-1)'])  \n",
    "    inv_yhat = scaler.inverse_transform(yhat.reshape(-1,1))\n",
    "    pred_list.append(inv_yhat[-1])\n",
    "    \n",
    "  add_dates = [df.index[-1] + pd.DateOffset(days=x) for x in range(0,n_pred+1) ]\n",
    "  future_dates = pd.DataFrame(index=add_dates[1:],columns=df.columns)\n",
    "\n",
    "  df_predict = pd.DataFrame(pred_list, index=future_dates[-n_pred:].index, columns=['FORECAST'])\n",
    "  \n",
    "  df_predict.index = pd.to_datetime(df_predict.index)\n",
    "  df.index = pd.to_datetime(df.index)\n",
    "  dfans = pd.concat([df, df_predict], axis=1, join=\"outer\")\n",
    "  return rmse,dfans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "x36Ov-mn_BRw"
   },
   "outputs": [],
   "source": [
    "def uni_forecast(model_list = ['LSTM'], data_source='wri', reservoir_name='KRS', noofdays=90):  \n",
    "  rmse = {}\n",
    "  df = pd.DataFrame()\n",
    "  if 'LSTM' in model_list:\n",
    "    rmse['LSTM'], dflstm = pred_lstm_uni(data_source, reservoir_name, noofdays)\n",
    "    dflstm['MODEL'] = 'LSTM'\n",
    "    df = pd.concat([df,dflstm], axis=0, join=\"outer\")\n",
    "    dfensemblewt = dflstm.copy()\n",
    "    dfensemble = dflstm.copy()\n",
    "\n",
    "  if 'SVR' in model_list:\n",
    "    rmse['SVR'], dfsvr = pred_svr_uni(data_source, reservoir_name, noofdays)\n",
    "    dfsvr['MODEL'] = 'SVR'\n",
    "    df = pd.concat([df,dfsvr], axis=0, join=\"outer\")\n",
    "    dfensemblewt = dfsvr.copy()\n",
    "    dfensemble = dfsvr.copy()\n",
    "\n",
    "  if 'XGBOOST'in model_list:\n",
    "    rmse['XGBOOST'], dfxgb = pred_xgb_uni(data_source, reservoir_name, noofdays)\n",
    "    dfxgb['MODEL'] = 'XGBOOST'\n",
    "    df = pd.concat([df,dfxgb], axis=0, join=\"outer\")\n",
    "    dfensemblewt = dfxgb.copy()\n",
    "    dfensemble = dfxgb.copy()\n",
    "\n",
    "  dfensemblewt['MODEL'] = 'ENSEMBLE(WEIGHTED)'\n",
    "  dfensemblewt['FORECAST'].values[:] = 0\n",
    "  dfensemble['MODEL'] = 'ENSEMBLE(MEAN)'\n",
    "  dfensemble['FORECAST'].values[:] = 0\n",
    "  total = 0\n",
    "  for model in model_list:\n",
    "    wt = 0\n",
    "    score = rmse[model]\n",
    "    if score <=2:\n",
    "      wt = 1\n",
    "    elif score<=3:\n",
    "      wt = 0.8\n",
    "    elif score<=5:\n",
    "      wt = 0.6\n",
    "    elif score<=10:\n",
    "      wt = 0.4\n",
    "    elif score<=15:\n",
    "      wt = 0.2\n",
    "    else:\n",
    "      wt = 0.1\n",
    "    dfensemble['FORECAST'] += (df[df['MODEL']==model]['FORECAST'])\n",
    "    dfensemblewt['FORECAST'] += (wt * df[df['MODEL']==model]['FORECAST'])\n",
    "    total += wt\n",
    "  dfensemble['FORECAST'] /= len(model_list)\n",
    "  dfensemblewt['FORECAST'] /= total\n",
    "  dfans = pd.concat([df, dfensemble], axis=0, join=\"outer\")\n",
    "  dfans = pd.concat([dfans, dfensemblewt], axis=0, join=\"outer\")\n",
    "  return rmse, dfans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "id": "4fba6823",
    "outputId": "6731898a-4fb4-44e5-ef70-b25e64e72933",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash app running on http://127.0.0.1:8005/\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# palette = px.colors.qualitative.Plotly\n",
    "\n",
    "# sample data\n",
    "df = pd.DataFrame({'Forecast': [1,10,7,5, np.nan, np.nan, np.nan]\n",
    "                    })\n",
    "\n",
    "# app setup\n",
    "app = JupyterDash(external_stylesheets=[dbc.themes.SLATE])\n",
    "\n",
    "# input controls\n",
    "controls = dbc.Card(\n",
    "      [dbc.FormGroup(\n",
    "            [\n",
    "                #dbc.Label(\"Forecast\"),\n",
    "                                dcc.Checklist(\n",
    "                                    id=\"display_columns\",                    \n",
    "                                    options=[{\"label\": col + ' ', \"value\": col} for col in df.columns],\n",
    "                                    value=[],\n",
    "                                    labelStyle={'display': 'inline-block', 'width': '12em', 'line-height':'0.5em'}\n",
    "                    #clearable=False,\n",
    "                    #multi = True\n",
    "                ),\n",
    "            ], \n",
    "        ),\n",
    "\n",
    "        dbc.FormGroup(\n",
    "            [dbc.Label(\"\"),]\n",
    "        ),\n",
    "    ],\n",
    "    body=True,\n",
    "    style = {'font-size': 'large'})\n",
    "\n",
    "app.layout = dbc.Container(\n",
    "    [\n",
    "        html.H1(\"Button for predictions\"),\n",
    "        html.Hr(),\n",
    "        dbc.Row([\n",
    "            dbc.Col([controls],xs = 4),\n",
    "            dbc.Col([\n",
    "                dbc.Row([\n",
    "                    dbc.Col(dcc.Graph(id=\"predictions\")),\n",
    "                ])\n",
    "            ]),\n",
    "        ]),\n",
    "        html.Br(),\n",
    "        dbc.Row([\n",
    " \n",
    "        ]), \n",
    "    ],\n",
    "    fluid=True,\n",
    ")\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"predictions\", \"figure\"),\n",
    "    [Input(\"display_columns\", \"value\"),\n",
    "\n",
    "    ],\n",
    ")\n",
    "def make_graph(display_columns):\n",
    "    \n",
    "    #you can call the forecast function here and disable that is not necessary.\n",
    "    models = ['LSTM','SVR','XGBOOST']\n",
    "    data_source = 'wri'\n",
    "    reservoir_name = 'KRS'\n",
    "    noofdays = 90\n",
    "\n",
    "    rmse, df = uni_forecast(models, data_source, reservoir_name, noofdays)\n",
    "    s = 'Present Storage Forecast in TMC'\n",
    "    dfactual = df[df['MODEL']==models[0]]\n",
    "    plot_data = [\n",
    "        go.Scatter(\n",
    "            x=dfactual.index,\n",
    "            y=dfactual['PRESENT_STORAGE_TMC'],\n",
    "            name='ACTUAL'\n",
    "        )]\n",
    "\n",
    "    models.append('ENSEMBLE(MEAN)')\n",
    "    models.append('ENSEMBLE(WEIGHTED)')\n",
    "    for model in models:\n",
    "      dftemp = df[df['MODEL']==model]\n",
    "      if model in rmse:\n",
    "        s = s+'<br> RMSE for ' + model + ': '+str(round(rmse[model],2))\n",
    "      new_data = go.Scatter(\n",
    "              x=dftemp.index,\n",
    "              y=dftemp['FORECAST'],\n",
    "              name=model+' FORECAST'\n",
    "          )\n",
    "      plot_data.append(new_data) \n",
    "\n",
    "    plot_layout = go.Layout(\n",
    "            title=s,\n",
    "            title_font_size=12\n",
    "        )\n",
    "    fig = go.Figure(data=plot_data, layout=plot_layout)\n",
    "    # py.iplot(fig)\n",
    "\n",
    "    # # main trace\n",
    "    # y = 'Forecast'\n",
    "    # fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    # if 'Forecast' in display_columns:\n",
    "        \n",
    "    #     fig.add_trace(go.Scatter(name=y, x=df.index, y=df[y], mode = 'lines'), secondary_y=False)\n",
    "    \n",
    "    # # prediction trace\n",
    "    # #if 'Predicted_prices' in display_columns:\n",
    "    #  #   fig.add_trace(go.Scatter(name = 'predictions', x=df.index, y=df['Predicted_prices'], mode = 'lines'), secondary_y=False)\n",
    "    \n",
    "    # # Aesthetics\n",
    "    # fig.update_layout(margin= {'t':30, 'b':0, 'r': 0, 'l': 0, 'pad': 0})\n",
    "    # fig.update_layout(hovermode = 'x')\n",
    "    # fig.update_layout(showlegend=True, legend=dict(x=1,y=0.85))\n",
    "    # fig.update_layout(uirevision='constant')\n",
    "    # fig.update_layout(template='plotly_dark',\n",
    "    #                   plot_bgcolor='#272B30', \n",
    "    #                   paper_bgcolor='#272B30')\n",
    "    # fig.update_layout(title = \"Forecast Plot\")\n",
    "    return(fig)\n",
    "\n",
    "app.run_server(mode='external', port = 8005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07111d1c"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Checkbox_plot_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
